Description: Limit queue lengths for batman and broadcast packets
 This patch limits the queue lengths of batman and broadcast packets. BATMAN
 packets are held back for aggregation and jittered to avoid interferences.
 Broadcast packets are stored to be sent out multiple times to increase the
 probability to be received by other nodes in lossy environments.
 .
 Especially in extreme cases like broadcast storms, the queues have been seen to
 run full, eating up all the memory and triggering the infamous OOM killer. With
 the queue length limits introduced in this patch, this problem is avoided.
 .
 Each queue is limited to 256 entries for now, resulting in 1 MB of maximum
 space available in total for typical setups (assuming one packet including
 overhead does not require more than 2000 byte). This should also be reasonable
 for smaller routers, otherwise the defines can be tweaked later.
 .
 This third version of the patch does not increase the local broadcast sequence
 number when the queue is already full.
Origin: backport, http://git.open-mesh.net/?p=batman-adv;a=commit;h=7e9eac0b803b6e9db3284fcecbb0b0b011926485
Author: Simon Wunderlich <siwu@hrz.tu-chemnitz.de>

---
diff --git a/aggregation.c b/aggregation.c
index b8338ce23c84367dbbd939718cc21b1ba484c12d..5ab1184982896f96ee5fec67fe6d7ff8aa35fecf 100644
--- a/aggregation.c
+++ b/aggregation.c
@@ -95,6 +95,7 @@ static bool can_aggregate_with(struct batman_packet *new_batman_packet,
 	return false;
 }
 
+#define atomic_dec_not_zero(v)          atomic_add_unless((v), -1, 0)
 /* create a new aggregated packet and add this packet to it */
 static void new_aggregated_packet(unsigned char *packet_buff,
 			   int packet_len,
@@ -106,13 +107,26 @@ static void new_aggregated_packet(unsigned char *packet_buff,
 	struct forw_packet *forw_packet_aggr;
 	unsigned long flags;
 
+	/* own packet should always be scheduled */
+	if (!own_packet) {
+		if (!atomic_dec_not_zero(&batman_queue_left)) {
+			bat_dbg(DBG_BATMAN, "batman packet queue full\n");
+			return;
+		}
+	}
+
 	forw_packet_aggr = kmalloc(sizeof(struct forw_packet), GFP_ATOMIC);
-	if (!forw_packet_aggr)
+	if (!forw_packet_aggr) {
+		if (!own_packet)
+			atomic_inc(&batman_queue_left);
 		return;
+	}
 
 	forw_packet_aggr->packet_buff = kmalloc(MAX_AGGREGATION_BYTES,
 						GFP_ATOMIC);
 	if (!forw_packet_aggr->packet_buff) {
+		if (!own_packet)
+			atomic_inc(&batman_queue_left);
 		kfree(forw_packet_aggr);
 		return;
 	}
diff --git a/main.c b/main.c
index 2c2f243390fc67ac1f7fa2772cedaeead2ef115c..fbde05a396f702c1342298aa561af1524fa561fd 100644
--- a/main.c
+++ b/main.c
@@ -46,6 +46,9 @@ atomic_t originator_interval;
 atomic_t vis_interval;
 atomic_t vis_mode;
 atomic_t aggregation_enabled;
+atomic_t bcast_queue_left;
+atomic_t batman_queue_left;
+
 int16_t num_hna;
 int16_t num_ifs;
 
@@ -87,6 +90,8 @@ int init_module(void)
 					 * for debugging now. */
 	atomic_set(&vis_mode, VIS_TYPE_CLIENT_UPDATE);
 	atomic_set(&aggregation_enabled, 1);
+	atomic_set(&bcast_queue_left, BCAST_QUEUE_LEN);
+	atomic_set(&batman_queue_left, BATMAN_QUEUE_LEN);
 
 	/* the name should not be longer than 10 chars - see
 	 * http://lwn.net/Articles/23634/ */
diff --git a/main.h b/main.h
index 81f03a0f0fc19751b96b10a85629d36cfc409d4f..6e559b725c345072063aa02d837b1d93d40e388c 100644
--- a/main.h
+++ b/main.h
@@ -69,6 +69,8 @@
 #define MODULE_ACTIVE 1
 #define MODULE_DEACTIVATING 2
 
+#define BCAST_QUEUE_LEN		256
+#define BATMAN_QUEUE_LEN 	256
 
 /*
  * Debug Messages
@@ -134,6 +136,8 @@ extern atomic_t originator_interval;
 extern atomic_t vis_interval;
 extern atomic_t vis_mode;
 extern atomic_t aggregation_enabled;
+extern atomic_t bcast_queue_left;
+extern atomic_t batman_queue_left;
 extern int16_t num_hna;
 extern int16_t num_ifs;
 
diff --git a/send.c b/send.c
index c485324cd8f7a476876927ceccd2513fe5c6b6f9..ec3de7426e7545d37e8431546527bd51d2a6d71f 100644
--- a/send.c
+++ b/send.c
@@ -362,19 +362,32 @@ static void _add_bcast_packet_to_list(struct forw_packet *forw_packet,
 			   send_time);
 }
 
-void add_bcast_packet_to_list(struct sk_buff *skb)
+#define atomic_dec_not_zero(v)          atomic_add_unless((v), -1, 0)
+/* add a broadcast packet to the queue and setup timers. broadcast packets
+ * are sent multiple times to increase probability for beeing received.
+ *
+ * This function returns NETDEV_TX_OK on success and NETDEV_TX_BUSY on
+ * errors.
+ *
+ * The skb is not consumed, so the caller should make sure that the
+ * skb is freed. */
+int add_bcast_packet_to_list(struct sk_buff *skb)
 {
 	struct forw_packet *forw_packet;
 
+	if (!atomic_dec_not_zero(&bcast_queue_left)) {
+		bat_dbg(DBG_BATMAN, "bcast packet queue full\n");
+		goto out;
+	}
+
 	forw_packet = kmalloc(sizeof(struct forw_packet), GFP_ATOMIC);
+
 	if (!forw_packet)
-		return;
+		goto out_and_inc;
 
 	skb = skb_copy(skb, GFP_ATOMIC);
-	if (!skb) {
-		kfree(forw_packet);
-		return;
-	}
+	if (!skb)
+		goto packet_free;
 
 	skb_reset_mac_header(skb);
 
@@ -385,6 +398,14 @@ void add_bcast_packet_to_list(struct sk_buff *skb)
 	forw_packet->num_packets = 0;
 
 	_add_bcast_packet_to_list(forw_packet, 1);
+	return NETDEV_TX_OK;
+
+packet_free:
+	kfree(forw_packet);
+out_and_inc:
+	atomic_inc(&bcast_queue_left);
+out:
+	return NETDEV_TX_BUSY;
 }
 
 void send_outstanding_bcast_packet(struct work_struct *work)
@@ -419,8 +440,10 @@ void send_outstanding_bcast_packet(struct work_struct *work)
 	if ((forw_packet->num_packets < 3) &&
 	    (atomic_read(&module_state) != MODULE_DEACTIVATING))
 		_add_bcast_packet_to_list(forw_packet, ((5 * HZ) / 1000));
-	else
+	else {
 		forw_packet_free(forw_packet);
+		atomic_inc(&bcast_queue_left);
+	}
 }
 
 void send_outstanding_bat_packet(struct work_struct *work)
@@ -446,6 +469,10 @@ void send_outstanding_bat_packet(struct work_struct *work)
 	    (atomic_read(&module_state) != MODULE_DEACTIVATING))
 		schedule_own_packet(forw_packet->if_incoming);
 
+	/* don't count own packet */
+	if (!forw_packet->own)
+		atomic_inc(&batman_queue_left);
+
 	forw_packet_free(forw_packet);
 }
 
diff --git a/send.h b/send.h
index b2ddf631fb58a71635141c9ba329c60fecb273e4..bbfa234085224c79d7652ecb5e986ba19cc7d474 100644
--- a/send.h
+++ b/send.h
@@ -33,7 +33,7 @@ void schedule_forward_packet(struct orig_node *orig_node,
 			     struct batman_packet *batman_packet,
 			     uint8_t directlink, int hna_buff_len,
 			     struct batman_if *if_outgoing);
-void add_bcast_packet_to_list(struct sk_buff *skb);
+int  add_bcast_packet_to_list(struct sk_buff *skb);
 void send_outstanding_bcast_packet(struct work_struct *work);
 void send_outstanding_bat_packet(struct work_struct *work);
 void purge_outstanding_packets(void);
diff --git a/soft-interface.c b/soft-interface.c
index 4c0daf1a2e2162d9fa02927379ad0c497c59a272..62c4250eee003e8d1b0fd2d0835693ea02d45acc 100644
--- a/soft-interface.c
+++ b/soft-interface.c
@@ -212,10 +212,10 @@ int interface_tx(struct sk_buff *skb, struct net_device *dev)
 		/* set broadcast sequence number */
 		bcast_packet->seqno = htons(bcast_seqno);
 
-		bcast_seqno++;
+		/* broadcast packet. on success, increase seqno. */
+		if (add_bcast_packet_to_list(skb) == NETDEV_TX_OK)
+			bcast_seqno++;
 
-		/* broadcast packet */
-		add_bcast_packet_to_list(skb);
 		/* a copy is stored in the bcast list, therefore removing
 		 * the original skb. */
 		kfree_skb(skb);
